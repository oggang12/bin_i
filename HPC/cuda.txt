CUDA:

CUDA is a parallel computing platform and an API model that was developed by Nvidia.
Using CUDA, one can utilize the power of Nvidia GPUs to perform general computing tasks,
such as multiplying matrices and performing other linear algebra operations,
instead of just doing graphical calculations. Using CUDA, developers can now harness the potential
of the GPU for general purpose computing (GPGPU).

CUDA âˆ’ Compute Unified Device Architecture. It is an extension of C programming,
an API model for parallel computing created by Nvidia. Programs written using CUDA harness the power of GPU.
Thus, increasing the computing performance.

Parallelism:

Dynamic parallelism in CUDA is supported via an extension to the CUDA programming model
that enables a CUDA kernel to create and synchronize new nested work.
Basically, a child CUDA kernel can be called from within a parent CUDA kernel and then optionally
synchronize on the completion of that child CUDA Kernel. The parent CUDA kernel can consume the output
produced from the child CUDA kernel, all without CPU involvement.